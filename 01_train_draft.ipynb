{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62b5fe-9b7a-4a8b-9bc0-2026d82c5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508b37c-d84a-4c25-9110-34af0edf5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tqdm -q\n",
    "#! pip install pretty_midi -q\n",
    "#! pip install librosa -q\n",
    "#! pip install -U matplotlib -q\n",
    "#! pip install torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1af9a-b75a-4eb2-888b-a1bb19033942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import pretty_midi\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356730d-4351-49c3-883c-ea2a6d62a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    where am i?\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "PATH = os.getcwd() + '/'\n",
    "data_path = PATH + 'data/'\n",
    "midi_path = data_path + '/nesmdb_midi/train/'\n",
    "\n",
    "print(f'PATH: {PATH}')\n",
    "print(f'data path: {data_path}')\n",
    "print(f'midi path: {midi_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53826e1b-e610-4787-9e46-00b115e27966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    device\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a4ca0-fabc-4bb8-8693-7471d871ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    load midi files\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sample_space = sorted(os.listdir( midi_path ))\n",
    "#sample_space = np.random.choice( sample_space, 100 )\n",
    "\n",
    "print(f'sample space size: {len(sample_space)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c368e05-e9f7-4d74-9ee4-1e9fbaf21869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    load midi files\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "midi = {}\n",
    "midi_error = []\n",
    "\n",
    "for s in tqdm( sample_space ):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        # piano roll representation\n",
    "        aux = pretty_midi.PrettyMIDI( midi_path + s ).get_piano_roll( fs=100 )\n",
    "\n",
    "        midi[ s ] = aux\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        #print(f'error: {s}')\n",
    "        midi_error.append(s)\n",
    "        \n",
    "print(f'corrupted files: {len(midi_error)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e0737-d32d-4988-8f6d-8f40a6e63b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    encode/decode\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dims):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 128*128, 512 )\n",
    "        self.linear2 = nn.Linear(512, latent_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        \n",
    "        return self.linear2(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dims):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(latent_dims, 512)\n",
    "        self.linear2 = nn.Linear(512, 128*128)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \n",
    "        z = F.relu(self.linear1(z))\n",
    "        z = torch.sigmoid(self.linear2(z))\n",
    "        \n",
    "        return z.reshape((-1, 1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229bda6-a5a9-4834-b2d5-b11714830f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    autoencoder\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dims):\n",
    "        \n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(latent_dims)\n",
    "        self.decoder = Decoder(latent_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        z = self.encoder(x)\n",
    "        \n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af97324-dca8-47e8-844b-de422ec26096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    train autoencoder\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def train(autoencoder, data, epochs=20):\n",
    "    \n",
    "    opt = torch.optim.Adam(autoencoder.parameters())\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        for x in data:\n",
    "            \n",
    "            x = x.to(device) # GPU\n",
    "            opt.zero_grad()\n",
    "            x_hat = autoencoder(x)\n",
    "            loss = ((x - x_hat)**2).sum()\n",
    "            \n",
    "            print(f'loss: {loss}')\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ce2eb-4c79-4482-85d9-96f690403530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    data loader\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class AudioDataset( Dataset ):\n",
    "    \n",
    "    def __init__(self, midi_files):\n",
    "        \n",
    "        self.midi_files = midi_files\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len( self.midi_files )\n",
    "\n",
    "    def __getitem__( self, idx ):\n",
    "        \n",
    "        midi_file = self.midi_files[ idx ]\n",
    "        \n",
    "        # log-frequency spectogram\n",
    "        log_spec = librosa.amplitude_to_db(\n",
    "            librosa.feature.melspectrogram(\n",
    "                y=None, \n",
    "                sr=100, \n",
    "                S=midi_file.T, \n",
    "                n_fft=2048, \n",
    "                hop_length=512, \n",
    "                power=2.0, \n",
    "                n_mels=128), \n",
    "            ref=1.0\n",
    "        )\n",
    "        \n",
    "        # convert to pytorch tensor\n",
    "        log_spec_tensor = torch.from_numpy( log_spec ).float().unsqueeze(0)  # add channel dimension\n",
    "\n",
    "        return log_spec_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addcc1a-b694-4572-8233-e5e71352660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    train encoder\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "midi_files = [ midi[ k ] for k in midi ]\n",
    "midi_files = [ x for x in midi_files if x.shape[1] > 0 ]\n",
    "\n",
    "dataset = AudioDataset( midi_files )\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    batch_size=128, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "latent_dims = 2\n",
    "autoencoder = Autoencoder( latent_dims ).to( device )\n",
    "autoencoder = train( autoencoder, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd47c0-c1c6-4112-8d48-0c2bbcc7afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6796054-d3a0-4317-90bc-ff9c7386bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    viz\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def plot_latent(autoencoder, data, num_batches=100):\n",
    "    \n",
    "    for i, x in enumerate(data):\n",
    "        \n",
    "        z = autoencoder.encoder( x.to(device) )\n",
    "        \n",
    "        z = z.to('cpu').detach().numpy()\n",
    "        \n",
    "        plt.scatter(z[:, 0], z[:, 1], cmap='tab10')\n",
    "        \n",
    "        if i > num_batches:\n",
    "            plt.colorbar()\n",
    "            break\n",
    "    \n",
    "plot_latent( autoencoder, dataloader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690fa310-d282-44bf-ad1b-2627db041c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
