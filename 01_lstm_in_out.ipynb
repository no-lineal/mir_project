{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    where am i?\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "PATH = os.getcwd() + '/'\n",
    "data_path = PATH + 'data/'\n",
    "train_path = data_path + '/nesmdb_midi/train/'\n",
    "output_path = data_path + 'output/'\n",
    "corpus_path = output_path + 'corpus/'\n",
    "\n",
    "print(f'PATH: {PATH}')\n",
    "print(f'data path: {data_path}')\n",
    "print(f'train path: {train_path}')\n",
    "print(f'output path: {output_path}')\n",
    "print(f'corpus path: {corpus_path}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    device\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    load corpus\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "corpus = json.load( open( output_path + 'corpus.json', 'r' ) )\n",
    "\n",
    "print(f'corpus raw size: {len(corpus)}')\n",
    "print(f'unique chars: {len(set(corpus))}')\n",
    "print('\\n')\n",
    "\n",
    "corpus = corpus[:53712*10]\n",
    "n_vocab = len(set(corpus))\n",
    "\n",
    "print(f'corpus cut size: {len(corpus)}')\n",
    "print(f'unique chars: { n_vocab }')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "    split and encode corpus in sequences\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "corpus_chars = sorted( list( set( corpus ) ) )\n",
    "mapping = dict((c, i) for i, c in enumerate( corpus_chars ))\n",
    "\n",
    "length = 100\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "\n",
    "for i in tqdm(range( 0, len(corpus) - length, 1 )):\n",
    "\n",
    "    input = corpus[ i:i + length ]\n",
    "    output = corpus[ i + length ] \n",
    "\n",
    "    features.append( [ mapping[char] for char in input ] )\n",
    "    targets.append( mapping[output] )\n",
    "\n",
    "print(f'corpus sequences: {len(features)}')\n",
    "print(f'targets: {len(targets)}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "\n",
    "    input format: [ sample, time steps, features ]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X = torch.tensor( features, dtype=torch.float32 ).reshape( len(features), length, 1 )\n",
    "X = X / float( n_vocab )\n",
    "\n",
    "y = torch.tensor( targets, dtype=torch.float32 )\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "    lstm\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class bitLSTM( nn.Module ):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM( input_size=1, hidden_size=512, num_layers=1, batch_first=True )\n",
    "        self.dropout = nn.Dropout( p=0.2 )\n",
    "        self.fc = nn.Linear( in_features=512, out_features=n_vocab )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x, _ = self.lstm( x )\n",
    "        x = x[ : , -1 , : ]\n",
    "        x = self.dropout( x )\n",
    "        x = self.fc( x )\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = bitLSTM().to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "    train\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "optimizer = torch.optim.Adam( model.parameters(), lr=0.001 )\n",
    "criterion = nn.CrossEntropyLoss( reduction='sum' )\n",
    "dataloader = DataLoader( TensorDataset( X, y ), batch_size=batch_size, shuffle=True )\n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range( epochs ):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(dataloader):\n",
    "\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model( x_batch )\n",
    "        loss = criterion( y_hat, y_batch.long() )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if train_loss < best_loss:\n",
    "\n",
    "            best_loss = train_loss\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "    print(f'epoch: {epoch} | loss: {train_loss}')\n",
    "\n",
    "torch.save( best_model, output_path + 'model.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitmusic38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
